{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from subprocess import check_output\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/Users/yuwei/Documents/学习资料/7008/作业/project/twitchdata-update.csv',encoding='latin-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking some information of the data\n",
    "print(df.shape)\n",
    "print(df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explore if the following data have a normal distribution\n",
    "df['Watch times(Minutes)_log'] = np.log(df['Watch time(Minutes)'])\n",
    "df['Average viewers_log'] = np.log(df['Average viewers'])\n",
    "df['Peak viewers_log'] = np.log(df['Peak viewers'])\n",
    "df['Followers gained_log'] = np.log(df['Followers gained'])\n",
    "\n",
    "plt.figure(figsize = (12,10))\n",
    "plt.subplot(221)\n",
    "g1 = sns.distplot(df['Watch times(Minutes)_log'])\n",
    "g1.set_title(\"Watch times(Minutes) LOG DISTRIBUITION\", fontsize=8)\n",
    "\n",
    "plt.subplot(222)\n",
    "g1 = sns.distplot(df['Average viewers_log'])\n",
    "g1.set_title(\"Average viewers LOG DISTRIBUITION\", fontsize=8)\n",
    "\n",
    "plt.subplot(223)\n",
    "g1 = sns.distplot(df['Peak viewers_log'])\n",
    "g1.set_title(\"Peak viewers LOG DISTRIBUITION\", fontsize=8)\n",
    "\n",
    "plt.subplot(224)\n",
    "g1 = sns.distplot(df['Followers gained_log'])\n",
    "g1.set_title(\"Followers gained LOG DISTRIBUITION\", fontsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(12,8))\n",
    "wordcloud = WordCloud(\n",
    "                          background_color='white',\n",
    "                          width=1920,\n",
    "                          height=1280\n",
    "                         ).generate(\" \".join(df.Language))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Language count\")\n",
    "print(df.Language.value_counts()[:21])\n",
    "\n",
    "\n",
    "plt.figure(figsize = (14,15))\n",
    "\n",
    "plt.subplot(311)\n",
    "g = sns.countplot('Language', data=df, palette=\"Set1\")\n",
    "g.set_xticklabels(g.get_xticklabels(),rotation=45)\n",
    "g.set_title(\"Counting the Video Language \", fontsize=15)\n",
    "g.set_xlabel(\"\", fontsize=12)\n",
    "g.set_ylabel(\"Count\", fontsize=12)\n",
    "\n",
    "plt.subplot(312)\n",
    "g1 = sns.boxplot(x='Language', y='Watch times(Minutes)_log', data=df, palette=\"Set2\")\n",
    "g1.set_xticklabels(g.get_xticklabels(),rotation=45)\n",
    "g1.set_title(\"Views Distribuition by Language\", fontsize=20)\n",
    "g1.set_xlabel(\"\", fontsize=15)\n",
    "g1.set_ylabel(\"Watch times(Minutes)(log)\", fontsize=15)\n",
    "\n",
    "plt.subplot(313)\n",
    "g1 = sns.boxplot(x='Language', y='Followers gained_log', data=df, palette=\"Set3\")\n",
    "g1.set_xticklabels(g.get_xticklabels(),rotation=45)\n",
    "g1.set_title(\"Followers Distribuition by Language\", fontsize=20)\n",
    "g1.set_xlabel(\"\", fontsize=15)\n",
    "g1.set_ylabel(\"Followers gained(log)\", fontsize=15)\n",
    "\n",
    "plt.subplots_adjust(hspace = 0.7, top = 0.9)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polish = df.loc[df['Language'] == \"Polish\"]\n",
    "plt.figure(figsize = (20,8))\n",
    "french.head(25).plot.bar(x='Channel', y='Average viewers',color = 'blue',  align='edge')\n",
    "plt.title('Comparing the average viewers for the first 25 French streamers')\n",
    "plt.xlabel('Streamers')\n",
    "plt.ylabel('Count') \n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['QualityOutput'] =  df['Watch time(Minutes)'] / df['Stream time(minutes)'] * 100\n",
    "df['Trend_Streamer'] =  df['Peak viewers'] / df['Average viewers'] * 100000\n",
    "plt.figure(figsize = (20,12))\n",
    "\n",
    "g1 = sns.distplot(df['QualityOutput'], color='red',hist=False, label=\"Watch\")\n",
    "\n",
    "g1 = sns.distplot(df['Trend_Streamer'], color='green',hist=False, label=\"Viewer\")\n",
    "g1.set_title('CONVERT RATE DISTRIBUITION', fontsize=16)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.grid()\n",
    "plt.plot(df[\"Watch time(Minutes)\"]/max(df[\"Watch time(Minutes)\"]))\n",
    "plt.plot(df[\"Stream time(minutes)\"]/max(df[\"Stream time(minutes)\"]), \"y+\")\n",
    "plt.title('Comparing watch time and stream time (normalized)')\n",
    "plt.xlabel(\"Streamer's rank\")\n",
    "plt.ylabel('Normalized value')\n",
    "plt.legend([\"Normalized watch time\", \"Normalized Stream time\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope, intercept, r_value, p_value, std_err = sp.stats.linregress (range(0,1000), df[\"Stream time(minutes)\"]/max(df[\"Stream time(minutes)\"]))\n",
    "def predict(x):\n",
    "   return slope * x + intercept\n",
    "line = predict(range(0,1000))\n",
    "plt.plot(line)\n",
    "plt.plot(df[\"Watch time(Minutes)\"]/max(df[\"Watch time(Minutes)\"]))\n",
    "plt.title('Comparing watch time and stream time (regression)')\n",
    "\n",
    "plt.xlabel(\"Streamer's rank\")\n",
    "plt.ylabel('Normalized value')\n",
    "plt.legend([\"Normalized watch time\", \"Normalized Stream time (regression)\"])\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print(\"Correlation: {}\".format(r_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(df[['Channel', 'Watch time(Minutes)', 'Stream time(minutes)', 'Followers','Peak viewers','Average viewers','Followers gained','Views gained','Partnered','Mature','Language']].corr(), annot = True)\n",
    "plt.title('Overall relation between columns of the Dataset', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_follower = np.mean(df.iloc[:,5])\n",
    "max_follower = np.max(df.iloc[:,5])\n",
    "mean_stream = np.mean(df.iloc[:,3])\n",
    "max_stream = np.max(df.iloc[:,3])\n",
    "popularity = pd.cut(df.iloc[:,5],bins=[0,mean_follower,max_follower],labels=['less popular','popular'])\n",
    "stream = pd.cut(df.iloc[:,3],bins=[0,mean_stream,max_stream],labels=['less frequent','frequent'])\n",
    "df.insert(6,'level_of_popularity',popularity )\n",
    "df.insert(3,'frequency_of_streaming',stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_make = LabelEncoder()\n",
    "df[\"level_of_popularity\"] = lb_make.fit_transform(df[\"level_of_popularity\"])\n",
    "df[\"Language_code\"] = lb_make.fit_transform(df[\"Language\"])\n",
    "df[\"Partnered\"] = lb_make.fit_transform(df[\"Partnered\"])\n",
    "df[\"Mature\"] = lb_make.fit_transform(df[\"Mature\"])\n",
    "df[\"frequency_of_streaming\"] = lb_make.fit_transform(df[\"frequency_of_streaming\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification\n",
    "y = df['level_of_popularity']\n",
    "X = pd.concat([df['frequency_of_streaming'],df['Partnered'],df['Mature'],df['Language_code']],axis=1)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=100)\n",
    "reg = classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "#Print the results \n",
    "result = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(result)\n",
    "result1 = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\",)\n",
    "print (result1)\n",
    "result2 = accuracy_score(y_test,y_pred)\n",
    "print(\"Accuracy:\",result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "df['Language'] = np.where(df['Language'] != 'English', 'Others', df['Language'])\n",
    "model = smf.ols(formula='Followers~C(Language)+C(frequency_of_streaming)+C(Mature)', data=df)\n",
    "res = model.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
